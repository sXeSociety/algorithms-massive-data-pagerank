{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMbmml7bZstnZkP0DS5WznX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sXeSociety/algorithms-massive-data-pagerank/blob/main/notebooks/01_dataset_download.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Algorithms for Massive Data – Project 3**\n",
        "*Notebook 01 – Dataset Download & Initial Exploration*\n"
      ],
      "metadata": {
        "id": "WVI8BGY8alEg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "4Se028haUOAT",
        "outputId": "81d05051-d994-4abf-c581-e1f7a08d9749",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/algorithms-massive-data-pagerank\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<module 'src.utils_io' from '/content/algorithms-massive-data-pagerank/src/utils_io.py'>"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ],
      "source": [
        "# Change current working directory to the project root\n",
        "%cd /content/algorithms-massive-data-pagerank\n",
        "\n",
        "# Import main libraries\n",
        "import os\n",
        "import sys\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import importlib"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Project root is now the current working directory\n",
        "project_root = os.getcwd()\n",
        "print(\"Project root:\", project_root)\n",
        "\n",
        "# Make sure we can import from the src package\n",
        "if project_root not in sys.path:\n",
        "    sys.path.append(project_root)"
      ],
      "metadata": {
        "id": "Iooi2HqUf1p3",
        "outputId": "0d492a23-c141-4087-ffe1-83495f5bd9de",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Project root: /content/algorithms-massive-data-pagerank\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define data directories inside the project\n",
        "data_dir = os.path.join(project_root, \"data\")\n",
        "raw_dir = os.path.join(data_dir, \"raw\")\n",
        "processed_dir = os.path.join(data_dir, \"processed\")"
      ],
      "metadata": {
        "id": "cE0greR9A6FJ"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create data directories if they do not exist\n",
        "from src.utils_io import ensure_dirs\n",
        "ensure_dirs([data_dir, raw_dir, processed_dir])"
      ],
      "metadata": {
        "id": "Ne1lTJGyA9_E",
        "outputId": "f7146d24-773b-46c8-e5bf-9c97fb3c8c8c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Directory already exists: /content/algorithms-massive-data-pagerank/data\n",
            "Directory already exists: /content/algorithms-massive-data-pagerank/data/raw\n",
            "Directory already exists: /content/algorithms-massive-data-pagerank/data/processed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define some global variables\n",
        "use_subsample = True\n",
        "subsample_fraction = 0.05\n",
        "seed = 42"
      ],
      "metadata": {
        "id": "aBLG1D5hg7HG"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print recap\n",
        "print(\"\\nSetup Recap\")\n",
        "print(f\"use_subsample = {use_subsample}\")\n",
        "print(f\"raw_dir       = {raw_dir}\")\n",
        "print(f\"processed_dir = {processed_dir}\")"
      ],
      "metadata": {
        "id": "aGHeUvk9hO1C",
        "outputId": "18050a19-9180-4dea-8e98-87369c6bf83b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Setup Recap\n",
            "use_subsample = True\n",
            "raw_dir       = /content/algorithms-massive-data-pagerank/data/raw\n",
            "processed_dir = /content/algorithms-massive-data-pagerank/data/processed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# In the version saved on GitHub, keep \"xxxxxx\" for username and key.\n",
        "# When running locally on Colab, replace \"xxxxxx\" with your actual credentials.\n",
        "os.environ[\"KAGGLE_USERNAME\"] = \"xxxxxx\"\n",
        "os.environ[\"KAGGLE_KEY\"] = \"xxxxxx\""
      ],
      "metadata": {
        "id": "2v-x6ANBixhk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the Kaggle dataset identifier\n",
        "kaggle_dataset = \"mohamedbakhet/amazon-books-reviews\""
      ],
      "metadata": {
        "id": "3_YmBmlM3Fgo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if the dataset already exists in RAW_DIR\n",
        "existing_files = []\n",
        "for f in os.listdir(raw_dir):\n",
        "    if f.lower().endswith(\".csv\"):\n",
        "        existing_files.append(f)\n",
        "\n",
        "if existing_files:\n",
        "  print(\"Dataset already present in raw_dir, skipping download.\")\n",
        "else:\n",
        "  print(\"Dataset not found in raw_dir, downloading from Kaggle.\")\n",
        "  !kaggle datasets download -d {kaggle_dataset} -p {raw_dir} --unzip\n",
        "  print(\"Download extraction completed.\")\n",
        "  print(\"Files now in raw_dir:\")\n",
        "  for f in os.listdir(raw_dir):\n",
        "    print(\" -\", f)"
      ],
      "metadata": {
        "id": "vFAGPEvu3nB2",
        "outputId": "e0d0191d-d13c-48a8-c8c6-f48753db9122",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset not found in raw_dir, downloading from Kaggle.\n",
            "Dataset URL: https://www.kaggle.com/datasets/mohamedbakhet/amazon-books-reviews\n",
            "License(s): CC0-1.0\n",
            "Downloading amazon-books-reviews.zip to /content/data/raw\n",
            " 99% 1.05G/1.06G [00:08<00:00, 116MB/s] \n",
            "100% 1.06G/1.06G [00:08<00:00, 130MB/s]\n",
            "Download extraction completed.\n",
            "Files now in raw_dir:\n",
            " - Books_rating.csv\n",
            " - books_data.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ratings_path = os.path.join(raw_dir, \"Books_rating.csv\")\n",
        "np.random.seed(seed)\n",
        "\n",
        "# Does the file exist?\n",
        "if not os.path.exists(ratings_path):\n",
        "  print(f\"ERROR: ratings file not found at {ratings_path}\")\n",
        "\n",
        "else:\n",
        "  if use_subsample:\n",
        "    print(\"Using subsample mode\")\n",
        "    # Charge the whole file\n",
        "    df_ratings = pd.read_csv(ratings_path)\n",
        "    print(f\"Full dataset shape before subsample: {df_ratings.shape}\")\n",
        "    # Fractional sample\n",
        "    df_ratings = df_ratings.sample(\n",
        "        frac = subsample_fraction,\n",
        "        random_state = seed)\n",
        "    print(f\"Subsampled dataset shape: {df_ratings.shape}\")\n",
        "    # Save subsample in processed/\n",
        "    subsample_path = os.path.join(processed_dir, \"ratings_subsample.csv\")\n",
        "    df_ratings.to_csv(subsample_path, index = False)\n",
        "    print(f\"Subsample saved to: {subsample_path}\")\n",
        "\n",
        "  else:\n",
        "     print(\"Loading full dataset (no subsample)...\")\n",
        "     df_ratings = pd.read_csv(ratings_path)\n",
        "     print(f\"Full dataset shape: {df_ratings.shape}\")\n",
        "\n",
        "  # Some diagnostic informations\n",
        "  print(\"Final dataframe shape:\", df_ratings.shape)\n",
        "  print(df_ratings.columns)\n",
        "  print(df_ratings.head())"
      ],
      "metadata": {
        "id": "gTnMGBiDExKK",
        "outputId": "c357c620-5fb2-4d3a-d6fc-99eb6703bebb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using subsample mode\n",
            "Full dataset shape before subsample: (3000000, 10)\n",
            "Subsampled dataset shape: (150000, 10)\n",
            "Subsample saved to: /content/data/processed/ratings_subsample.csv\n",
            "Final dataframe shape: (150000, 10)\n",
            "Index(['Id', 'Title', 'Price', 'User_id', 'profileName', 'review/helpfulness',\n",
            "       'review/score', 'review/time', 'review/summary', 'review/text'],\n",
            "      dtype='object')\n",
            "                 Id                                              Title  Price  \\\n",
            "2945667  B0006CR6U4  A dictionary of the Targumim, the Talmud Babli...    NaN   \n",
            "2352586  0897166159           Espresso Coffee: Professional Techniques    NaN   \n",
            "1531260  0736693408  The First King of Shannara (The Sword of Shann...    NaN   \n",
            "941910   0395051029             Wuthering Heights (Riverside editions)    NaN   \n",
            "2582125  4770016050  A Cat, a Man, and Two Women (Japans Modern Wri...    NaN   \n",
            "\n",
            "                User_id                 profileName review/helpfulness  \\\n",
            "2945667  A303XPDO694V6X                       Ariel                2/6   \n",
            "2352586  A3780H4TM9RMB8                David barnes                0/1   \n",
            "1531260  A1AX6VPDQQZDPV                   M Carlton                4/4   \n",
            "941910   A35RQKCCCQ62O0                       LadyJ                0/0   \n",
            "2582125  A2IJQDE1I4SIJT  David C. Arnold \"master D\"                1/2   \n",
            "\n",
            "         review/score  review/time                          review/summary  \\\n",
            "2945667           4.0   1122163200                                 Jastrow   \n",
            "2352586           2.0   1356912000                            NOT the book   \n",
            "1531260           5.0   1105574400             Great (what do you expect?)   \n",
            "941910            4.0   1353888000                               Satisfied   \n",
            "2582125           5.0   1167955200  Ordered 09/02/2006, still on backorder   \n",
            "\n",
            "                                               review/text  \n",
            "2945667  Jastrow made a great workthis dictionary can h...  \n",
            "2352586  Extremely disappointed by the SHORT length and...  \n",
            "1531260  This, like all of Brook's Shannara series book...  \n",
            "941910   I enjoyed this classic. I didn't know the stor...  \n",
            "2582125  I would love to read this book. Have accepted ...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute the distinct number of users and book\n",
        "# Is the subsample still rich or did I cut it too aggresively?\n",
        "n_users = df_ratings[\"User_id\"].nunique()\n",
        "n_books = df_ratings[\"Id\"].nunique()\n",
        "print(f\"Distinct users: {n_users}\")\n",
        "print(f\"Distinct books: {n_books}\")"
      ],
      "metadata": {
        "id": "_NX1ee2RjkXc",
        "outputId": "8a8666ba-3eef-4e29-c649-f27616f072bb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Distinct users: 95746\n",
            "Distinct books: 53940\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Review distribution per user and book\n",
        "# Is this graph just a collection of almost-isolated nodes, or do we have a network where information can actually flow?\n",
        "user_reviews = df_ratings[\"User_id\"].value_counts()\n",
        "book_reviews = df_ratings[\"Id\"].value_counts()\n",
        "\n",
        "print(\"\\nReviews per user:\")\n",
        "print(f\"min:    {user_reviews.min()}\")\n",
        "print(f\"median: {user_reviews.median()}\")\n",
        "print(f\"mean:   {user_reviews.mean():.2f}\")\n",
        "print(f\"max:    {user_reviews.max()}\")\n",
        "\n",
        "print(\"\\nReviews per book:\")\n",
        "print(f\"min:    {book_reviews.min()}\")\n",
        "print(f\"median: {book_reviews.median()}\")\n",
        "print(f\"mean:   {book_reviews.mean():.2f}\")\n",
        "print(f\"max:    {book_reviews.max()}\")"
      ],
      "metadata": {
        "id": "jGR5Htv9komZ",
        "outputId": "5c4e4cd4-1e5c-43bc-87da-7516be4fd2d9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Reviews per user:\n",
            "min:    1\n",
            "median: 1.0\n",
            "mean:   1.28\n",
            "max:    290\n",
            "\n",
            "Reviews per book:\n",
            "min:    1\n",
            "median: 1.0\n",
            "mean:   2.78\n",
            "max:    339\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Already active items\n",
        "# How many items are actually doing something interesting for the graph, and not just appearing once and disappearing?\n",
        "# A user with two or more reviews can create at least one pair of books that share the same user.\n",
        "active_users = (user_reviews >= 2).sum()\n",
        "active_books = (book_reviews >= 2).sum()\n",
        "print(f\"\\nUsers with >= 2 reviews: {active_users}\")\n",
        "print(f\"Books with >= 2 reviews: {active_books}\")"
      ],
      "metadata": {
        "id": "tLI5QJDJmenY",
        "outputId": "f3f6094a-85f5-45b7-ecca-cbf49a68c245",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Users with >= 2 reviews: 11647\n",
            "Books with >= 2 reviews: 19848\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# df_ratings_clean is going to be the subsample to use for describing the dataset\n",
        "# Rename columns to make them more understandable and keep only what's useful\n",
        "df_ratings_clean = df_ratings.rename(columns = {\n",
        "    \"User_id\": \"user_id\",\n",
        "    \"Id\": \"book_id\",\n",
        "    \"review/score\": \"rating\"\n",
        "})[[\"user_id\", \"book_id\", \"rating\"]]\n",
        "\n",
        "print(\"Shape df_ratings_clean:\", df_ratings_clean.shape)\n",
        "print(df_ratings_clean.head())\n",
        "\n",
        "clean_path = os.path.join(processed_dir, \"ratings_subsample_clean.csv\")\n",
        "df_ratings_clean.to_csv(clean_path, index = False)\n",
        "print(f\"Clean subsample saved in: {clean_path}\")"
      ],
      "metadata": {
        "id": "h6P9KoR4z6KG",
        "outputId": "dd347d5f-77b2-4985-ecc9-94fad4df6321",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape df_ratings_clean: (150000, 3)\n",
            "                user_id     book_id  rating\n",
            "2945667  A303XPDO694V6X  B0006CR6U4     4.0\n",
            "2352586  A3780H4TM9RMB8  0897166159     2.0\n",
            "1531260  A1AX6VPDQQZDPV  0736693408     5.0\n",
            "941910   A35RQKCCCQ62O0  0395051029     4.0\n",
            "2582125  A2IJQDE1I4SIJT  4770016050     5.0\n",
            "Clean subsample saved in: /content/data/processed/ratings_subsample_clean.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# df_core is the dataset I am going to use to create the graph and do PageRank\n",
        "# The graph will have way less noise, it is going to be more connected and interesting\n",
        "min_reviews = 2\n",
        "user_counts = df_ratings_clean[\"user_id\"].value_counts()\n",
        "book_counts = df_ratings_clean[\"book_id\"].value_counts()\n",
        "\n",
        "# Active users and books with at least two reviews\n",
        "active_users = user_counts[user_counts >= min_reviews].index\n",
        "active_books = book_counts[book_counts >= min_reviews].index\n",
        "\n",
        "df_core = df_ratings_clean[\n",
        "    df_ratings_clean[\"user_id\"].isin(active_users)\n",
        "    & df_ratings_clean[\"book_id\"].isin(active_books)\n",
        "].copy()\n",
        "\n",
        "print(\"Shape df_core:\", df_core.shape)\n",
        "print(\"Distinct users in core:\", df_core[\"user_id\"].nunique())\n",
        "print(\"Distinct books in core:\", df_core[\"book_id\"].nunique())\n",
        "print(df_core.head())\n",
        "\n",
        "core_path = os.path.join(processed_dir, \"ratings_core_for_graph.csv\")\n",
        "df_core.to_csv(core_path, index = False)\n",
        "print(f\"Core dataset saved in: {core_path}\")"
      ],
      "metadata": {
        "id": "RBVSPVKs44o9",
        "outputId": "785f1ccb-bd0d-47db-a644-2f56bee77430",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape df_core: (30736, 3)\n",
            "Distinct users in core: 11104\n",
            "Distinct books in core: 10592\n",
            "                user_id     book_id  rating\n",
            "941910   A35RQKCCCQ62O0  0395051029     4.0\n",
            "2379833  A319KYEIAZ3SON  0670569798     5.0\n",
            "2911594  A2X86K2EZCV0U1  B000GRDY1O     4.0\n",
            "2682023  A1JLKPA3EPLFCP  0774032448     5.0\n",
            "2306673  A1I2O9Y3X3HXLS  B000GRORC4     5.0\n",
            "Core dataset saved in: /content/data/processed/ratings_core_for_graph.csv\n"
          ]
        }
      ]
    }
  ]
}